{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo and Model Analysis\n",
    "This notebook is used to demonstrate the usage of LION and to analyze the model, component-by-component.\n",
    "\n",
    "The below two cells are just copied from demo.py, to load a checkpoint and sample a point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/jw/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/jw/.cache/torch_extensions/py38_cu111/emd_ext/build.ninja...\n",
      "Building extension module emd_ext...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module emd_ext...\n",
      "load emd_ext time: 0.066s\n",
      "utils/utils.py: USE_COMET=1, USE_WB=0\n",
      "Using /home/jw/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/jw/.cache/torch_extensions/py38_cu111/_pvcnn_backend/build.ninja...\n",
      "Building extension module _pvcnn_backend...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module _pvcnn_backend...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 23:41:01.333 | INFO     | utils.model_helper:import_model:106 - import: models.shapelatent_modules.PointNetPlusEncoder\n",
      "2023-07-03 23:41:01.337 | INFO     | models.shapelatent_modules:__init__:29 - [Encoder] zdim=128, out_sigma=True; force_att: 0\n",
      "2023-07-03 23:41:01.337 | INFO     | utils.model_helper:import_model:106 - import: models.latent_points_ada.PointTransPVC\n",
      "2023-07-03 23:41:01.337 | INFO     | models.latent_points_ada:__init__:38 - [Build Unet] extra_feature_channels=0, input_dim=3\n",
      "2023-07-03 23:41:01.397 | INFO     | utils.model_helper:import_model:106 - import: models.latent_points_ada.LatentPointDecPVC\n",
      "2023-07-03 23:41:01.398 | INFO     | models.latent_points_ada:__init__:241 - [Build Dec] point_dim=3, context_dim=1\n",
      "2023-07-03 23:41:01.398 | INFO     | models.latent_points_ada:__init__:38 - [Build Unet] extra_feature_channels=1, input_dim=3\n",
      "2023-07-03 23:41:01.458 | INFO     | models.vae_adain:__init__:50 - [Build Model] style_encoder: models.shapelatent_modules.PointNetPlusEncoder, encoder: models.latent_points_ada.PointTransPVC, decoder: models.latent_points_ada.LatentPointDecPVC\n",
      "2023-07-03 23:41:02.709 | INFO     | utils.model_helper:import_model:106 - import: models.score_sde.resnet.PriorSEDrop\n",
      "2023-07-03 23:41:02.710 | INFO     | models.score_sde.resnet:__init__:135 - [Build Resnet Prior] Has condition input: False; clipforge 0; learn_mixing_logit=1, \n",
      "2023-07-03 23:41:02.711 | INFO     | models.score_sde.resnet:__init__:178 - [temb_fun] embedding_type=positional, embedding_scale=1.0, embedding_dim=128\n",
      "2023-07-03 23:41:03.012 | INFO     | models.latent_points_ada_localprior:__init__:43 - [Build Prior Model] nclass=4, embed_dim=64, use_att=True,extra_feature_channels=1, dropout=0.1, time_emb_scales=1.0 num_point=2048\n",
      "2023-07-03 23:41:03.013 | INFO     | models.latent_points_ada:__init__:38 - [Build Unet] extra_feature_channels=1, input_dim=3\n",
      "2023-07-03 23:41:03.077 | INFO     | utils.diffusion_pvd:__init__:36 - [Build Discrete Diffusion object] beta_start=0.0001, beta_end=0.02, mode=linear, num_steps=1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO finish loading from ./lion_ckpt/snapshot\n"
     ]
    }
   ],
   "source": [
    "# Import and load model\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "from default_config import cfg as config\n",
    "from models.lion import LION\n",
    "from utils.vis_helper import plot_points\n",
    "from huggingface_hub import hf_hub_download \n",
    "\n",
    "model_path = './lion_ckpt/snapshot' # path to model checkpoint\n",
    "model_config = './lion_ckpt/cfg.yml' # path to model config\n",
    "\n",
    "config.merge_from_file(model_config)\n",
    "lion = LION(config)\n",
    "lion.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAGwCAIAAABEkjw5AAAn5UlEQVR4nO2deXQUVdrwn6rq6s5OFkggnbCEsGRBBA0jjqDOKCA4CTADL6iIBsdvZlxm+RyPnuMc5SiK8zqOzui8vC5HhW8ITMKmICHIDKKAEhBBliQQyEoWsvbeXdv3R0HbdvZOV9Wt7uf3hye0XXWfdP/y3LXupSRJAgTRGlrrABAEAEVECAFFRIgARUSIAEVEiABFRIgARUSIAEVEiABFRIgARUSIwKB1AKEARVEA4DdZ6n3R7//K//SCU6wymBFVxc9CxAtmxD7pmbp8c5tfwoM+8mKv+N6BoihMioAZsS96pq6+kplXI0mSvIb52dnr5eifLyjiAHj1GtIlPX9A7foHq+b+CMAe38wXQK0dtqCI/RFAA863/ef7Sq83H05sIQaKOACDbywGdk9MkzLYRuydnn4MaIy3j9JPRYza9QWOHSBEgBkRIQIUESECFBEhAhQRIQIUESECFBEhAhQRIQIUESECFBEhAhQRIQIUESECFBEhAhQRIQIUESECFBEhAhQRIQIUESECfGald0RRdDgcAMCyrMFgoGkan3VSFHxUwB9Jknie53me4zhRFOUXKYpiGAalVA4U8QdIkuTxeERRpCiK4zjfbUZ8N3IwXAelDBYo4jUkSRIEgeM4uP48nsfj8d3axvedKGXQQREBfKpj321r+hLR70Lf6ttgMLAsyzAMSjlUUEQQRVFuDvpaCADeFwd5Hz8p5QYlSjlIwlpE3+qYpv1HsoYqot+dRVGUP1uapmUpDQaDn+uIl/AVUZIkjuMEQehLjuGI6FeQLKVcEMuycvWNUvoSpiKKouhtAvZlQ7BE9CJ/1N7qm6Zp3zZlsErRKWEnYq/9kl4Juoh+YQBK6UN4ieg7TDigYYqK6BeV706e3jZlWEkZRiLKibD/6tgX1UT0JWylDAsRB18d+6KJiL74SSnPMTIMI/e+tYpKIUJfxL6GCQdEcxF9kXzwnfiWe99aRxcEQlnE/ocJB4QoEX3pNVPqXcqQFXHAYcIBIVZEX0JGytAUcTDDhAPC87zscXBjUw7ZSO8fj76kDDURA+uX9IruRPTFT0rvEiFipQwpEYc0TDgguhbRl55Syr1voqQMHRHlfskwq2NfQkZEX/zalLKUJCymDIVnVnyr4+CO+g64HlF3+P6VyqMKPM8DASt8dS9iwMOEiJ+U8mM6oJGUOhax5+J+rSPSMX5SchznK6W3TalcAHqdvvT+BcvVMVoYROSZG29vhuM4h8Px2GOPffnll8oVqsuMGJRhQmQwyFICgNVqjYqKUq4gnYnorY6D3i9B+sdut8fGxip3fz2JGNxhQmRI2Gy2mJgY5e6vGxHVr47RdV8cDke4Z0TlhgmRweN0OiMjI5W7P+kiYnVMCJIkKZoFyBURhwnJQYV5YEJFDOIiGiQoKP1FkCgiztqRhu86CYUgS8RhLu5HFMLlcinaUwGiRBz+4n5EIex2e3R09FCv8p28HvDNpGQdURTdbjdaSCYvvvhiR0dHQ0ODckVoL6KcCN1uNwDg8gUymTNnjiiKa9asqampGfxVQ2pWalw1kzxMSFo8GjJ27NhZs2a98847yhWhpYhD3QME0Qq73a7oRDNoJSLO2umLwDorQ0IDEXGYUHcovfQG1BdRbhQqPXGJBJfAqmZvlqGuHxHSz5vVtkHOgmihvghsDZj0Q/p/swZCoIW6w263K/qcAJAwjoiQj81mU3RVLKCIyGBwOBxKd1ZQxP7ATr2MCsM3GoiI367uUPoRPsCMiAwGFWZWUMRBMZj5e0GUmi1uDy+qEI/KqJARNZhZ0UXVbHFyx2o6kiKZnNS4s03Wry51/mhC/KTk6GM1XVe6XXdMSmJoOimapShKkiSPIJkM9FeXOw9d7MgeHV0wfQwAeHiRF6Uoo4L7xaiGy+UymUyKFkHQwljNEUWp3e6JizCYWKa23VHT7qgHaXxS1I5vm+o6XS0WV1wke7KhWxThy+rOjKSouZOSbho74ujlrvPN1vTEyN2nmr9rtjVbXAXTx3TYPc/uquh28b+/c/yPJiReanO4OCFrdIwu/gh7RenRXxTxeypbrOW1XSNjjPfkpIxNimrsdo6MMnCC1OXgqq/aatrtk5JjeEFy8+Kldnt9h7PL4TnTaGmze7qc3L8r2650uSJNjChKtR3O//d1/Vc1XTQFX1zsGBlj+vCrBk4QH56dPiVF2ZaWEqizSSRWzd8jSt//d0QkOz87xe50FR1v7LB7LE6eF8Hm6p6UHO3iBY4XGzudNe1OhoGxCRF2j3jV6mEYyhxv6nbym441flXTKUogSlDT4fzfL+tsbi42gtV1Na30t4YZEQDgQovtH4cupcdHLr5x9JgRUQcqrp5vts6ekCAJ3PkrtnYbNyKS7XBwvCRdtXq6nB6r51rfRRDgSrebEyReAp6XTl2xMxTUdTqF66c9fnW5y8TSBopKijU63Lx2v2LgeE+uVBQUEQDgb/+5+PXlDqDo2g7H7IykT880NXd7ys61GGm6ssXGS2AygIkBloFIlrrS/YMetIeTfP0SJGh3fP+CW5BoSnQDUDbucrtz/Mhok4He8W1TeW33fXmpualxav2KgeN0OgOYaPbNoIMZc8CqGTrsHk4AUaLijExDp+tkXbeBoVmGMtBUs8XFSQAALlktTrJxLpYBQfj+8gGznIeXTCwFkvjBV/XH6roYijpe02Xz8Beu2vLGJ2SnxIxLjMxJjaUJ+1i8BDCt4vcVy2MLA1yi/qkC8pJElQvtBw8vfni01uriZ2ckVrVYOUGaOjq2ssXW7XDvPdfaYXU7ePD9jAyDkM8PE0OxBpoCGB1rsrh5i4t3c6IEQAPQDDU1Jfq5BZOyxyg7UBcwS5curaure+edd2699VaWZQdzie8CxMEsRgQc0AaA883WZovrqtV9oq7zy+qOL6rbK5qtjZ2O3Wda3JxgToialBwV49PPEAHoISYvXpAMNJUca4yLZNrtnIsTJQAJQADgBam5221185xwrSlW3+msbLGRc+zIU089NXr06K1bt3Z2dipXSri3ERs6nf+paP3yYnur1cMyVATLdDs85Ze7GIYyUJIoQUKkcfaEBArgg68bvVeJQ5REAOhy8t1OngLwa/lHGmBGWuymrxvPXrEV3prebve8+Z/LHl78P7eNy0klIkdSFJWVlfWPf/xD0VLCuo0oiNL/HLrcYnEBAC+ILg7srmvNP1GQjCwlgXS53dFocU8ZdW3DDQMF5hHG2q7vmxYUwCC1lHp7Z2wEe+RyF0NTnQ5uZV4qDdDc7W61u187UD01JeahW9JT4pSd0hgQFSaaQauqmRAXaQqSoo217Y6mLhcnXqsrr/0vAEECkMAjgs0tnGywyS+umZ2alhTJXA/fSEN8ROCfIQXgESWPINrdgt0jVDbbBAmABrtbrGix7T139b0jdeW1XW02LZvUAa8BG9LDcWFXNUuS9J/Kq11OPiMpssnijjYyzd0uz/X60kCDkaF5QeQkcPESQ0GkATwCmAx0JEvFR7AnGqyX2lzexCYBeIYxyhbJ0jemxR2u7hAB6judT+8497ufZrg5AUCKYGgXJxysajvfZJuSEv2nhZOH+YsHTACP8PlNxhA6fKMtLRb3x6eb3bzo5oTzzVY3J3K+JkmQFGN0efhul8AJkgQQH2XMHBl109gR5bXd39RbOEk0MZS3jciJwAVkIgUwMpKanh6fGh8xwsR2ODlOkFps3Pq9VUDTFEV5BMnFiYIkWd32pm7XvKwOu0fMHhM7WvWaOrDl2UPtbGkj4mAGlpRAkqTEaGPmqJiGTke9k7M4eRGAZYAXr/U/eAna7VxCJLtsZvJ/KtuuWDxNFk+zxXO8rsvJAwA0W7iEyCDM1EkAV53SiTrLyUarzcMLkhwedLp9GwjAcxKAZPeIv9x8ZlS0ISaCWTVr7PiRkTelj1CteWO320eNGqV0KWE0fHOmsfs3Rade+rTixxMTTjVaKlps8VEGE0MZGXrSyIgIw7UxGYdHaLG6jtV0TUq+1jCSAJzXRw4pClpsQZup63Tx7XbOzQ/8NykBtNr5S+3udaUX/veL2qpWe7BiGBAVnhOAsKqav2u0tlrd39R2VjRbO+0eu1vgBWpkjMnu5scmxWamUKXnrgqiBAC8CLUdzjabx69HbGSA+mEiZ37Yv+m1XxxcKAoiWWZE5KAGloOCCqtiIawy4t3Zo24wx0kUVdPuzBgZHW2kRVGyOLmMkdHPLph8/6z0lBjWW9sJgmT38AAQF8HEmegolkqMMkQbGZfwg3v6/ktU3kIjDTPTY9feO0XNlqI6wzeatRHVLzTCwDR2uRgAo5GZMXbE7ImJ+862tFjdFjf/cmmVyUC7eZECYCgQJRDg2oSy5bp6Dk77tTMeEb67YjcZVP30sGoOMhQFDE0xBpqmgKXpn04ZdbHV1uXkHG7hQqutqdvlESQAkCTFE9twECTgBFUDVKdqDiMRo02G38zNePJfp7qd3Plm6/6K1roOJydIUSwvSOC5/u2SbCEAzM2MV7OBCFg1B51Wq/ulvZWtVjcA1HU6pOvy2TnC3fsBVa0OlUvEjBhknB6BpiDKaHBzQpuN8/tbGPyUsYZQAOMTI1Qu1OPxGI1GpUsJo17zuKSoZ++Z/NaKG24el0BTYLu22BUMFDAUZI6Kvjc3meSPgwa4a+rI15bmqF90aD48BdoterjBPAIAzPGRe880l55rbe52cbxI0fDzG1N/+9MMCqh7p6VcbLX/s7yhyULQ0l0AoABuGhv3+O3jI1hVn8BS5xE+CKuM6CUtIfKR28ZvKZx58Pe3/jRrVHpCFMNQBpo+Wd9V0WL72fTRO381a2yC2jVg/5jjTY/dPiFjpLKbFPZKyD5OqjmCIHh38P7dTyZWNFunp43gRXH9votOTvDwYsH0MfdOG73j2yutVo8kAUWBJPkvaFWZVwqmTjdr8KSVIAjqbKwaXusR5bP+fPeRHxljvC0zKTbCwFBUrjnOZGCmmeP+51DNrlPNvAgZo6JX5pkzk6OBAg1XUMYYmRvT1Fvl4IvD4Qh4NJvyYcA3h1FGlCRJFMW+TjOgKOr5hZPdvBjBMs3d7m8buhfkpDxxZ4aRof/vtjM17U5RlLihPiIQJDyC2GF1xkebQPWNn99++22Hw6H08fUQPiLKubD/w4UoipK7Av91s/neaSlRRkZ+5ysF2TUdjtON3R8crTfSFC9BXZtDtcFHmoIYk8FoYLzxywfFqWPkuHHjLBbLnDlzdu7cmZaWNqRrfZ/iGxBt1gUCgHz4njrI5wvB8NKJJEm1Hc5RMUaLi391X1VZRXvwAuyPN36RM2PsiFExJlEUvUnd+x3TNK2okd9+++1777330UcfBXyHQT5OGvoZ0a9RGDAURY1PigKAaJPh+XunXrGcrml3ODwCBRBpZHhBdA1iWeGQiGapF+7NmpedLP9TFo5hGAAQRVH+vQRBEAQBrp+nGXQpbTbbYNqIvX62+jgUUoVF2v03CodDQpTxX4/cDAAeQWBp+v4Pvrnc5uAEPiirEQw0xdDUr+aMW5CTPC6x9/EabyKUs6MsJQDI5wwHMU0O8jmB4X+VIZsRZQvl0Qfl+ptGhgGAhCi2nqYmJEWNjjPZPfy3DdaAvxYDBbERBgC4JydlbOLA/YOeaVL2Um6KMAwzzDSpzooHCFURvV0TdQ6Afu3nOZu+bvjgaF27g/vL0uzYCMPlNsfTO8/3fGeEgfLW4BEG2sWLAMAyQAHlEaSUWPbN5TdMS42FgEa4+kqTPM/T1xnqPYezGNH3VxiwAgzBqnkwHeTgEskyC3OSt31zxcjSk1NiEqONOalx39R3F39zRZSAoWFm+ojzLfbp5thlM1P/UHJWlGDx9JSX8rP+8XnNZ5VXn7tn8k1j41ut7sRo1hCMKjWIrcnhLL0Z0verWa9ZPqA06LcNVtckAHqOVly1ufefv3rLhISMkd8nlYZOJ8vQ6u/f4JcmYXBGvv7665mZmffff7/S4YVO1axc12SQ9Cx0VIzpvjz/sbe0BGVHhvui1zQp/+B9vaeUod9GDK4rmluoL3xbk746evt2XiNDX8Qgon6jMGTw69/4GinrqJqIul8GhhYGBZqmGYZhWTYiIsJoNMrjPjzPl5eXOxxqPJyg74zobXrjGdBBRE6ToiiuXbt2+vTps2fPVqFQvbYRsVGoKJIkvfjii52dnZs2bZL7MUqjy4yIFiqKJEnr169vaGjYuHGjOhaCHkXERqGiSJL017/+tbKycvPmzapZCLqrmtFCRZEk6e233z5x4sTWrVsNBlXd0FNGDMqyQqQvJEl69913Dx06tG3bNhUeZPZDHyJio1BpJEn68MMPS0tLd+7cqfSJuL2ig6oZLVSaAwcOfPzxx1VVVXv37o2I0OY5WtLrOLRQBc6cObN//36Xy1VUVKRVDERXzdg1UYEdO3bs3bv39OnTcXFx6hxE2ivkVs3YNVGB3bt3v/3223v27ImLiwNNP2oSMyJWx+qwb9++119/fc+ePQkJCVrHoqmIvS7SRgvV4d///vfLL7/86aefJiUlaR0LAGkZES1Uh0OHDj3//PN79uxR4QCVQUKQiNg1UYcjR448++yzu3fvHj16tNaxfA8pVTN2TdShvLz8qaee+vjjj81ms9ax/AAiMqKGTzyFFSdPnnzyySd37tw5duxYrWPxR2MRsVGoGt99992vf/3rbdu2TZgwQetYekHjelB+SAItVJpz58798pe/3Lp166RJk7SOpXc0E1GSpKeeemr37t0ejwctVJTKysrCwsJ//vOfWVlZWsfSJ1pmxGXLlh05cuSOO+546KGHduzYYberd+Jm+FBdXb169eqNGzdOmzZN61j6Q7OdHryIonj8+PHi4uKysrKJEyfm5+ffc889KpwwEw7U1tauWLHi/fffv/nmm4d5q8LCwt27dycnJ585cyYosfmhvYheRFE8depUSUnJ3r17zWZzfn7+okWL4uPjtY5Ll3g8ntbW1uXLl2/YsOGWW24Z/g0PHToUExPz4IMPKiQiQYN2NE3PmDFj3bp1J06ceOWVVxobG/Pz85csWfLRRx+1t7dDMDbhCx/+9Kc/zZgxY+bMmSkpKUG54dy5cxMTE4Nyq14hYhzRD4qicnNzc3Nzn3/++aqqqpKSkmXLlrEs29bWtnHjxuzsbOzc9E9LS8vhw4eLioocDkdnZyeZ4zV+EFQ190N3d/ePf/zjWbNmVVRUsCybn59fUFAwZswYNLInbW1tS5cuXbdu3fz584N755qamnvvvVehqpnEjNiTESNGlJWVpaamSpLU0NBQUlKyZs0anud/9rOfLV68OD09HY2U6ejoWLZs2QsvvBB0C5VGHxmxJ5IkNTU1bd++XR73WbRoUUFBwcSJE8PZyK6urp///OdPP/30kiVLlLi/ohlRryL60traunPnzm3btnV0dCxcuLCgoGDKlCnhZqTFYvnFL37x5JNPLl++XIn7r1y58uDBg21tbSkpKWvXrl2zZk1w7x8KInrp6OjYtWvXtm3brly5Mn/+/CVLlmRnZ4fDch6bzbZ8+fJHHnnkgQce0DqWAAkpEb10d3d/8skn27dvv3Tp0t13311QUHDjjTeGqpEOh2P58uWrVq16+OGHtY4lcEJTRC9Wq/XTTz/dtm1bRUXFT37yk4KCgry8vFAy0uVyrVy5cunSpY8++qiuWyMhLqIXp9O5b9++kpKSU6dOzZkzZ/HixbNnz1ZzkyElcLvdDzzwwIIFCx5//HFdWwjhI6IXt9v92WefFRcXHz9+fPbs2fn5+XV1datXr9ZdmuQ4bvXq1XPmzPnDH/6gdwshDEX0wnFcWVnZk08+abVaFy5cuGTJkttvv139zYcCg+f5wsLCm2666ZlnngkBC4GouWaVYVl26tSpf/zjH69cubJ69ep9+/bddtttjz766KeffupyubSOrj8EQfjVr341bdq0kLEQwjkj9kQQhCNHjmzbtu3AgQPZ2dkFBQXz5s2Liur9WEatEAThiSeeSE1NXbduXchYCChir4iiWF5eXlJSUlZWlpmZmZ+fv2DBAhKWSIqi+Lvf/S4+Pv7Pf/7z8Bu1paWlv/3tbwVBeOSRR5555pmgRBgwKGJ/yEski4uLS0tL09LS8vPzFy5cqNUSSVEUn376aYZh3nzzzeFbKAjC5MmT9+/fn5aWlpeXV1RUlJ2dHZQ4AwNFHBSSJJ05c6akpETeo2Px4sWLFi1Sc7OOd999d8+ePWPGjPnggw+C0sE/evToCy+8sG/fPgB45ZVXAODZZ58d/m0DJnw7K0OCoqhp06atXbv22LFjb7zxRltb27JlywoKCt5///3W1lYVTkA/e/ZsZ2fnxYsXt27dGpR7NjY2pqenyz+npaU1NjYG5bYBQ6iIxcXFOTk5NE0fP35c61h+AEVRU6dOfe65544ePbphwwan03nfffctWrRow4YNTU1NShgpHzbhdDq/+uqrw4cPr1ixIuhFkAChIubm5m7fvn3u3LlaB9InFEVNnDjx6aefPnz48EcffURR1MMPPzx//vy///3v9fX1wTJSPmyiqqrqgw8+kOeBgtVTNpvN9fX18s8NDQ2a70BCdBvxjjvueO2114b/BJo6+C6RdDgcM2bM8Hg8b775ZsDqyIdNHD169F//+hfLssGNluf5yZMnHzhwwGw25+Xlbd68OScnJ7hFDAlCM6IeoSgqNTX18ccfP3DgwIsvvrh79+7Kyso777zz1VdfraysHOofvHzYxBdffLFly5agWwgABoPhrbfemj9/flZW1vLly7W1EEjIiHfddVdzc7PvK+vWrSsoKAC9ZURfqquraZqeMGGCd4lkU1OTvEQyKytrwG6vfNjEJ598snPnTq22+VcZ7UXsB/2K2JOuri55iWRNTc1dd921ePHi6dOn92Xkpk2biouLP/74Y9LmdZRDHw9PhQDx8fGrVq1atWqVvETyjTfeqKqquvPOOxcvXnzzzTf7Grl169aioqI9e/aEj4UAABKRbN++3Ww2G43G5OTkefPmaR2OIjgcju3bt9933325ubm/+c1vysrKLBbLpk2b5syZY7FYtI5ObYiumsMEt9u9f//+kpKSQ4cOsSz79ddfh+FGKygiQdjt9ra2tnHjxmkdiAaEy/BNaWnplClTMjMz169fr3UsfRIdHR2eFkKYZETSVpogPQmLjHjs2LHMzMyMjAyj0bhixYpdu3ZpHZGyEDtT3w9hISJpK02UhvyZ+p7gOGIIQvJe2X0RFhmRtJUmSE/CIiPm5eVduHDh8uXLZrN5y5Ytmzdv1jqioNHPTL2+CAsRvStNBEEoLCzUfKVJEPnss8+0DiE4hIWIALBw4cKFCxdqHQXSJ2Exjhhu+C3F1cVXjCIOC+9Xjh/jMAmLXjNCPijisMBEGCxQRIQIUESECFBEhAhQRIQIUMRh4R2+oSgqlHYrVB8cR0SIADMiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgThcrzFcJC3+fLbrcr7ot//HXBH/56bhsnv6XUzsfDZIgszYjAZ/s50veoeDoRvRuyZunxzm1/Cgz7yYq/43oGi/Df+8/1nP1kwfBSUCdOM2PNr7uuL93ojSZJXET87e718mLVq+FTKMmEqohevXkO6pOcPAXgTbjmvf8K3aoaAso6vPYOstX0v6dmnCbfM1xdhLWLPBtyA9GzADehfPx3nfkoPt3wZ1iLCUBqLgd0zAAvDTUGZMG0j9pRgwNTo7aP0UxEPKb9S1/F7MeAb6ho8VQAhgjDNiAhpoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBGgiAgRoIgIEaCICBHoRsQzZ86UlZXhgW2him5EPH/+/MGDB202G8/zWseCBB/diAgAFEWJomi1Wh0OhyiKWoeDBBOdnddM0zRFUR6Ph+O4iIgIo9EYnqcbhx46ExEAKIpiGEaSJIfDwfM8wzBaR6QDGIZhWVbrKPpDT1WzL7KOWkehGwRB0DqEAdBfRvRCUZRcU2sdCOnoYqhBTxlRFx8oEhi6EREzX2ijGxGR0AZFRIgARUSIAEVEiABFRIhATyLi8E0IoxsRq6ur6+rqtI4CUQptRCwsLExOTs7NzR38JbGxsYTPliLDQRsRH3roodLS0iFdkpKSMmbMGIXiQTRHGxHnzp2bmJioSdEImeimjYiENigiQgR6EhGHb0IY3YhI07oJFQkAbb7dlStXzp49u7KyMi0t7f3339ckBoQotFmhXVRUpEm5CLFgfYcQAYqIEAGKiBCBnkTE4ZsQRjci4sNToY1uRERCGxQRIQIUESECHW85EhpwgvjR0bpuJ//L28bFRYbvyl/MiErh7ePzgujm+twDqaHT+fmFtuO1nUeqO/p5W8ijp4xI/vBNm839xYV2Ny9QQJ1tsrRY3B5ejDHRnACTUmJMBrqu01XRbB0Vw05Pi781I+F4bffnF66ebbJIIjy740xijGlT4U2pIyK1/j00QDciEjJ8wwtip4PjBCk1PgIAPLzI0NQnp5s6HdykUVF/3n/xQotdBIgyAAA4eAAAGoCh4Yvq9hiTQRAlu1uobIGj1Z0bDl0WfP6yPKLk7HJtLW/4/V2TNPnVtEU3IpJAY5fzTx+fb+xyzkwf8evbMy602N7+/BIAWFx8h80tAXC8JO+o7PDZ51sEkPdZ7nLyDID8BgEAeuR3CeBg1dUn7pxoYMKuyYQiDopWi3vTV7Un6jpPN1o5EWranU0WV0qM6WyTbUj3GbANWNXiaOxyjUuKCjhUnYIiDsCXF9ue23m2ycr5vX70UpcSxdEARkPYpUNAEXuFF8QTtZ3F3zSeqO28YvFXUFEEgNf2X/jvpbk0TUSbWDVQRH9EUbr//fJvG62alC4BnG6wcIJoosNrh3Dd1AKnT58+ffq0CgXtPNV0SiMLAcDIUE/cmWFiw8tC0ErE0tLSKVOmZGZmrl+/fpCXZGRkZGZmKhqVTPVVm4bDlTmpsfnTw3FDCw1EFAThscce27t377lz54qKis6dOzeYq2JjYyMjFR/p9fDinu+alS6lL2iA8BzNBk3aiMeOHcvMzMzIyACAFStW7Nq1Kzs7W/0weqWhy+nmNUuIf/uvaXMmjdSqdG3RICM2Njamp6fLP6elpTU2Ng7yQhWm+MYnRj3wozSlS+mVGWlxmckxEeHXOpTRTWdFHSgKbpmQpP6HwlIQF8U6PLjoQUXMZnN9fb38c0NDg9lsVj+GvjhZ3/3C7vMGBpRQgqWAu57TEyINN42Lr25zmONMidFs/g2pCTHG7DGxwS9VJ2ggYl5e3oULFy5fvmw2m7ds2bJ582b1Y+gLk4GmKSolLrLb6bG4BpaRAUiJZdsdvFuQKICZaTEXrtot7mu6mRgq0shEMNQtExPnZSXzIiRFsxevOmIimDmZI0eE8erDnmggosFgeOutt+bPny8IQmFhYU5OzmCuUmf1TU5q3F+XT2MZOj0hcu0n53edbo6PZDNGRR+pbgeKeu/+6bMmJB6saotk6Q4HPzUlelxStNFA/+3fF/95rCH/htHpCZGGiqt54xMmJ8c4eXFhTkrP+bqbx+PGkL1Akb/IT+aTTz75/PPPn3/+ed8XDQaDcpszcYJY0+4YlxjVanVvO3nljskjp6eN6P8SSZLcvEhah0P+iiMiIrQOpD9wiq9PWIaelBwDAGkJkb/9ycTBXEJRFGkW6gXsNSNEgCIiRIAiIkSgJxH10q9CAkA3IhLy8BSiELoREQltUESECFBEhAhQRIQIUESECPQkIg7fhDC6ERGHb0Ib3YiIhDYoIkIEKCJCBHoSETsrIYxuRCwvLz927JjWUSBKobGIxcXFOTk5NE0fP368/3fOmDEjLy9PnagQ9dFYxNzc3O3bt8+dO3fAd7IsiyM4IYzGz6xkZWVpGwBCCLppIyKhjXoZ8a677mpu/sFGW+vWrSsoKFAtAIRk1BPxs88+U60sRHdg1YwQgcYi7tixIy0t7ejRo4sWLZo/f37/b8YB7RBG417zkiVLlixZMph39hy7EUWR53mGwZ0VBoDjuOLi4sLCQuW2Zxk+et1yxGshDi4OhvLy8i+//PLdd99lWUK3INOliIIgCIJgMBiI/ViJgqbpv/zlLzfeeOPIkSNnzZq1f/9+rSPqBXJzdV8IgiCKIlo4JGiaPnXq1Kuvvup0OltbW7UOpxd0JiLHcaIosiyLFg4ViqIefPBBu90+fvz4wcypqoyeRJR7zSzLBtBBCckedwC/1OHDh/fu3Xvy5Mns7OwFCxYoEVVg6KaNSNO0tzoWhKHtcP3dd98VFRW9/PLLyoSmGffdd9+GDRvi4uKGdNXMmTO/+OKLRx55ZMuWLQoFFgC62TEWABYsWNDW1hbAhZIkiaIYegM9giAE/EtJkjRq1KjS0tLghhQwehIRCWH01EZEQhgUESECFBEhAhQR6YXBP0sULFBEpBcG/yxRsEARkV6ora3Nz8//+uuvP/zwQ3VKRBERf7wnu+fl5ZWVlQ3yZPdhopuZFUQhej5LtGrVKvlkd5qm7777bnVOdscBbcSfkpKS0tLS9957b8yYMVar1WQytbe3K10oVs1In6SkpDzwwAPqlBUuIqozHlFaWjplypTMzMz169crV4pMYWFhcnJybm5u0O9sNptPnDiRlpZ2/vz5jRs32my2oBfRC1J4cO7cuYqKittvv728vFyhIniez8jIqK6udrvdN9xww9mzZxUqSObzzz8/ceJETk5O0O/McdyECRMuXbrkdrunTp2amZkZ9CJ6Ei4ZMSsra8qUKYoWcezYMbmNbzQaV6xYsWvXLkWLmzt3bmKiImeQe092z8rKWrRokclkUqIUP8JFRBVobGxMT0+Xf05LS2tsbNQ2nuGwcOHCqqqq6urqxx9/XJ0SQ3D4Bvc20SMhKKJWe5uYzeb6+nr554aGBrPZrEkYQWTlypUHDx5sa2tLS0tbu3btmjVrlCsrBEXUiry8vAsXLly+fNlsNm/ZsmXz5s1aRzRcioqK1CtMhQ4RCWzfvt1sNhuNxuTk5Hnz5ilUyp49eyZNmpSRkfHSSy8pVISXFStWjB492mAwmM3m9957T+nilAZnVhAiwF4zQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIEKCJCBCgiQgQoIkIE/x9mGFYqtkzgAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=216x432 at 0x7FCD4F5B4520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a sample\n",
    "if config.clipforge.enable: # currently not used\n",
    "    input_t = [\"a swivel chair, five wheels\"] \n",
    "    device_str = 'cuda'\n",
    "    clip_model, clip_preprocess = clip.load(\n",
    "                        config.clipforge.clip_model, device=device_str)    \n",
    "    text = clip.tokenize(input_t).to(device_str)\n",
    "    clip_feat = []\n",
    "    clip_feat.append(clip_model.encode_text(text).float())\n",
    "    clip_feat = torch.cat(clip_feat, dim=0)\n",
    "    print('clip_feat', clip_feat.shape)\n",
    "else:\n",
    "    clip_feat = None\n",
    "output_latent = lion.sample(1 if clip_feat is None else clip_feat.shape[0], clip_feat=clip_feat)\n",
    "pts = output_latent['points']\n",
    "img_name = \"/tmp/tmp.png\"\n",
    "plot_points(pts, output_name=img_name)\n",
    "img = Image.open(img_name)\n",
    "display(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE: Global Encoder\n",
    "The encoder takes in a point cloud and outputs a latent vector. The input point cloud is first passed through the global encoder (`vae.style_encoder`) to get a global feature vector, in this paper referred to as the **global prior**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointNetPlusEncoder(\n",
      "  (mlp): Linear(in_features=64, out_features=256, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): PVConv(\n",
      "        (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
      "        (voxel_layers): Sequential(\n",
      "          (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): Swish()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (5): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (6): SE(32, 32)\n",
      "        )\n",
      "        (point_features): SharedMLP(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
      "            (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "            (2): Swish()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): PVConv(\n",
      "        (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
      "        (voxel_layers): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): Swish()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (5): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (6): SE(32, 32)\n",
      "        )\n",
      "        (point_features): SharedMLP(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "            (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "            (2): Swish()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): PointNetSAModule(\n",
      "        num_centers=1024, out_channels=32\n",
      "        (groupers): ModuleList(\n",
      "          (0): BallQuery(radius=0.1, num_neighbors=32, include coordinates)\n",
      "        )\n",
      "        (mlps): ModuleList(\n",
      "          (0): SharedMLP(\n",
      "            (layers): Sequential(\n",
      "              (0): Conv2d(35, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (2): Swish()\n",
      "              (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (5): Swish()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): PVConv(\n",
      "        (voxelization): Voxelization(resolution=16, normalized eps = 0)\n",
      "        (voxel_layers): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (2): Swish()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (5): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (6): SE(32, 32)\n",
      "        )\n",
      "        (attn): LinearAttention(\n",
      "          (to_qkv): Conv2d(32, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (to_out): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (point_features): SharedMLP(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "            (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "            (2): Swish()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): PointNetSAModule(\n",
      "        num_centers=256, out_channels=64\n",
      "        (groupers): ModuleList(\n",
      "          (0): BallQuery(radius=0.2, num_neighbors=32, include coordinates)\n",
      "        )\n",
      "        (mlps): ModuleList(\n",
      "          (0): SharedMLP(\n",
      "            (layers): Sequential(\n",
      "              (0): Conv2d(35, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "              (2): Swish()\n",
      "              (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (4): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              (5): Swish()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lion.vae.style_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Point Cloud: torch.Size([1, 2048, 3])\n",
      "Output Latent: mu=torch.Size([1, 128]), sigma=torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# random sample point cloud\n",
    "B, N = 1, 2048 # batch size, number of points\n",
    "input_pc = torch.randn(B, N, 3).cuda() # B, N, 3 (x, y, z)\n",
    "\n",
    "output_latent = lion.vae.style_encoder(input_pc)\n",
    "mu, sigma = output_latent['mu_1d'], output_latent['sigma_1d']\n",
    "\n",
    "print(f\"Input Point Cloud: {input_pc.shape}\")\n",
    "print(f\"Output Latent: mu={mu.shape}, sigma={sigma.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The architecture of the global encoder (`PointNetPlusEncoder`)\n",
    "The global encoder `PointNetPlusEncoder` consists of `PVConv` and ... (TODO) layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### PVConv (PVCNN)\n",
    "From the [PVCNN architecture](https://pvcnn.mit.edu/). One PVConv layer is conceptually similar to a convolutional layer, but applied to a point cloud. It takes an input point cloud of dim (B, 3, N) with a per-point feature vector of dim (B, C, N) and outputs a per-point feature vector of dim (B, C', N).\n",
    "\n",
    "The feature vector is initially just a copy of the point cloud (i.e. C=[xyz]), then the number of channels gradually gets increased, just like a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PVConv(\n",
      "  (voxelization): Voxelization(resolution=32, normalized eps = 0)\n",
      "  (voxel_layers): Sequential(\n",
      "    (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "    (2): Swish()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (5): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "    (6): SE(32, 32)\n",
      "  )\n",
      "  (point_features): SharedMLP(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (2): Swish()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "fused_features: torch.Size([1, 32, 2048])\n",
      "coords_input: torch.Size([1, 3, 2048]), True\n"
     ]
    }
   ],
   "source": [
    "pvconv = lion.vae.style_encoder.layers[0][0]\n",
    "print(pvconv)\n",
    "\n",
    "features = coords = input_pc.transpose(1, 2) # B, 3, N\n",
    "inputs = (features, coords, None) # (features, coords, time_embedding)\n",
    "\n",
    "# pvconv turns the 3-channel features into 32-channel features\n",
    "# coords_input is just the same as coords\n",
    "fused_features, coords_input, time_emb = pvconv(inputs)\n",
    "\n",
    "print(f\"fused_features: {fused_features.shape}\")\n",
    "print(f\"coords_input: {coords_input.shape}, {coords is coords_input}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Prior\n",
    "The global prior is a latent vector of size (128,) that encodes information about the entire shape. When given an input point cloud (for either reconstruction or completion), it is produced by the encoder of the VAE. On the other hand, when doing generation, it is sampled from a standard normal distribution, as in a standard VAE. However, in order to make the global prior more informative, we use a technique called **Latent Diffusion**, which is done by the `global_prior` module.\n",
    "The global prior is then used to condition the decoder of the VAE to produce the output point cloud.\n",
    "> Note: In this case, the shape of the global prior latent vector is actually (128, 1, 1), as you can see below, in order to use `Conv2D` with kernel size (1, 1) and stride 1 as a \"hacky way\" to learn a multiplicative scalar factor for each of the 128 channels of the input latent vector. I.e. the extra 1, 1 are the dummy width and heights of the latent vector.  \n",
    "> `TODO: so why not just use a Linear layer?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_latent_shape [128, 1, 1]\n",
      "local_latent_shape [8192, 1, 1]\n",
      "PriorSEDrop(\n",
      "  (act): SiLU()\n",
      "  (temb_fun): PositionalEmbedding()\n",
      "  (temb_layer): Sequential(\n",
      "    (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (input_layer): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (output_layer): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (all_modules): ModuleList(\n",
      "    (0): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (1): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (2): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (3): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (4): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (5): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (6): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "    (7): ResBlockSE_withdropout(2048, 2048, drop=0.300000)\n",
      "  )\n",
      ")\n",
      "output shape torch.Size([3, 128, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "global_prior, local_prior = lion.priors\n",
    "global_latent_shape, local_latent_shape = lion.vae.latent_shape()\n",
    "print('global_latent_shape', global_latent_shape)\n",
    "print('local_latent_shape', local_latent_shape)\n",
    "# print(global_prior)\n",
    "\n",
    "N = 3 # num samples\n",
    "\n",
    "x = torch.randn(size=(N, *global_latent_shape)).cuda()\n",
    "t = torch.ones(N, dtype=torch.int64).cuda()\n",
    "\n",
    "print(global_prior)\n",
    "\n",
    "print('output shape', global_prior(x, t.float()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
